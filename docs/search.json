[{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"data-source","dir":"Articles","previous_headings":"","what":"Data Source","title":"Calorie Placement Re-Simulation","text":"replicating re-analyses Francis & Thunell’s (2020) Meta-Psychology paper: Excess success “Don’t count calorie labeling : Calorie counts left side menu items lead lower calorie food choices”. ran power analyses 6 studies Dallas, Liu, Ubel’s (2019) study showing people order food significantly fewer calories calorie count placed left item right (calorie label). used power estimates calculate probability 6 6 studies significant, given observed power study. Re-analysis Re-analysis code Original paper Table 1 re-analysis paper provides parameters need.","code":""},{"path":[]},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"study-2","dir":"Articles","previous_headings":"Reanalyses","what":"Study 2","title":"Calorie Placement Re-Simulation","text":"’ll start S2 analysis straightforward. ’s -subjects design, 143 subjects saw calorie placement left mean calories ordered 1249.83 (SD = 449.07), 132 subjects saw calorie placement right mean calories ordered 1362.31 (SD = 447.35). Let’s first simulate single data table parameters set analysis. Wrap analysis function using tidy() function {broom} get results tidy table. Check works running single data set . Now, simulate data 500 times. Run analysis data set. Summarise p.value column get power. Compare value (0.518) value paper (0.5426).","code":"data <- sim_design(   between = list(placement = c(\"left\", \"right\")),   mu = c(left = 1249.83, right = 1362.31),   sd = c(left = 449.07, right = 447.35),   n = c(left = 143, right = 132),   dv = \"calories\" ) s2_analyse <- function(data) {   t.test(calories ~ placement, data = data) |>     broom::tidy() }  s2_analyse(data) ## # A tibble: 1 × 10 ##   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high ##      <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> ## 1    -80.4     1266.     1347.     -1.50   0.134      258.    -186.      24.9 ## # ℹ 2 more variables: method <chr>, alternative <chr> s2 <- sim_design(   between = list(placement = c(\"left\", \"right\")),   mu = c(left = 1249.83, right = 1362.31),   sd = c(left = 449.07, right = 447.35),   n = c(left = 143, right = 132),   dv = \"calories\",   rep = 500 ) s2_sim <- s2 |>   mutate(analysis = map(data, s2_analyse)) |>   select(-data) |>   unnest(analysis)  head(s2_sim) ## # A tibble: 6 × 11 ##     rep estimate estimate1 estimate2 statistic  p.value parameter conf.low ##   <int>    <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>    <dbl> ## 1     1   -161.      1204.     1365.     -2.74 0.00659       254.    -276. ## 2     2   -186.      1203.     1388.     -3.42 0.000732      266.    -293. ## 3     3   -150.      1225.     1375.     -2.78 0.00577       272.    -256. ## 4     4   -130.      1275.     1405.     -2.39 0.0176        272.    -237. ## 5     5    -93.9     1273.     1367.     -1.62 0.106         269.    -208. ## 6     6   -116.      1235.     1350.     -1.99 0.0472        272.    -230. ## # ℹ 3 more variables: conf.high <dbl>, method <chr>, alternative <chr> s2_power <- s2_sim |>   mutate(sig = p.value < .05) |>   summarise(power = mean(sig)) |>   pull(power)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"study-1","dir":"Articles","previous_headings":"Reanalyses","what":"Study 1","title":"Calorie Placement Re-Simulation","text":"Study 1 little complicated design includes “label” condition, decision rule supporting hypothesis complicated. data simulation relatively straightforward, though. Set analysis. , really just care three p-values, ’ll just return . can use function {emmeans} package check two pairwise comparisons. Let’s just replicate 100 times simulation doesn’t take long run first. can always increase later ’ve run sense checks. Run analysis data set. Calculating power little trickier , three p-values need significant support hypothesis. Compare value (0.44) value paper (0.4582).","code":"data <- sim_design(   between = list(placement = c(\"left\", \"right\", \"none\")),   mu = c(654.53, 865.41, 914.34),   sd = c(390.45, 517.26, 560.94),   n = c(45, 54, 50),   dv = \"calories\" ) afex::set_sum_contrasts() # avoids annoying afex message on each run ## setting contr.sum globally: options(contrasts=c('contr.sum', 'contr.poly')) afex_options(include_aov = TRUE) # we need aov for lsmeans  s1_analyse <- function(data) {   # main effect of placement   a <- afex::aov_ez(     id = \"id\",     dv = \"calories\",     between = \"placement\",     data = data   )      # contrasts   e <- emmeans(a, \"placement\")   c1 <- list(lr = c(-0.5, 0.5, 0),              ln = c(-0.5, 0, 0.5))   b <- contrast(e, c1, adjust = \"holm\") |>     broom::tidy()      data.frame(     p_all = a$anova_table$`Pr(>F)`[[1]],     p_1 = b$adj.p.value[[1]],     p_2 = b$adj.p.value[[2]]   ) }  s1_analyse(data) ##         p_all        p_1         p_2 ## 1 0.006394198 0.01023146 0.006030088 s1 <- sim_design(   between = list(placement = c(\"left\", \"right\", \"none\")),   mu = c(654.53, 865.41, 914.34),   sd = c(390.45, 517.26, 560.94),   n = c(45, 54, 50),   dv = \"calories\",   rep = 100 ) s1_sim <- s1 |>   mutate(analysis = map(data, s1_analyse)) |>   select(-data) |>   unnest(analysis)  head(s1_sim) ## # A tibble: 6 × 4 ##     rep   p_all    p_1     p_2 ##   <int>   <dbl>  <dbl>   <dbl> ## 1     1 0.411   0.505  0.367   ## 2     2 0.0378  0.446  0.0272  ## 3     3 0.00598 0.102  0.00282 ## 4     4 0.00177 0.473  0.00176 ## 5     5 0.107   0.277  0.0701  ## 6     6 0.00938 0.0260 0.00610 s1_power <- s1_sim |>   mutate(sig = (p_all < .05) &                 (p_1 < .05) &                 (p_2 < .05)  ) |>   summarise(power = mean(sig)) |>   pull(power)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"study-3","dir":"Articles","previous_headings":"Reanalyses","what":"Study 3","title":"Calorie Placement Re-Simulation","text":"Now can use pattern Study 1 analyse data Study 3. ’ll start repeated data set. data collected Hebrew language, reads right left, paired contrasts different. Run analysis data set. Compare value (0.37) value paper (0.3626).","code":"s3 <- sim_design(   between = list(placement = c(\"left\", \"right\", \"none\")),   mu = c(1428.24, 1308.66, 1436.79),   sd = c(377.02, 420.14, 378.47),   n = c(85, 86, 81),   dv = \"calories\",   rep = 100 ) s3_analyse <- function(data) {   # main effect of placement   a <- afex::aov_ez(     id = \"id\",     dv = \"calories\",     between = \"placement\",     data = data   )      # contrasts (reversed)   e <- emmeans(a, \"placement\")   c1 <- list(rl = c(0.5, -0.5, 0),              ln = c(0, -0.5, 0.5))   b <- contrast(e, c1, adjust = \"holm\") |>     broom::tidy()      data.frame(     p_all = a$anova_table$`Pr(>F)`[[1]],     p_1 = b$adj.p.value[[1]],     p_2 = b$adj.p.value[[2]]   ) } s3_sim <- s3 |>   mutate(analysis = map(data, s3_analyse)) |>   select(-data) |>   unnest(analysis)  head(s3_sim) ## # A tibble: 6 × 4 ##     rep    p_all     p_1      p_2 ##   <int>    <dbl>   <dbl>    <dbl> ## 1     1 0.0129   0.00795 0.0489   ## 2     2 0.000642 0.00226 0.000824 ## 3     3 0.00505  0.00486 0.0116   ## 4     4 0.000675 0.00603 0.000485 ## 5     5 0.00314  0.00705 0.00348  ## 6     6 0.0466   0.0587  0.0587 s3_power <- s3_sim |>   mutate(sig = (p_all < .05) &                 (p_1 < .05) &                 (p_2 < .05)  ) |>   summarise(power = mean(sig)) |>   pull(power)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"study-s1","dir":"Articles","previous_headings":"Reanalyses","what":"Study S1","title":"Calorie Placement Re-Simulation","text":"Now can use pattern Study 2 analyse data Study S1. can even reuse analysis function s2_analyse()!","code":"ss1 <- sim_design(   between = list(placement = c(\"left\", \"right\")),   mu = c(left = 185.94, right = 215.73),   sd = c(left = 93.92, right = 95.33),   n = c(left = 99, right = 77),   dv = \"calories\",   rep = 1000 ) ss1_sim <- ss1 |>   mutate(analysis = map(data, s2_analyse)) |>   select(-data) |>   unnest(analysis) ss1_power <- ss1_sim |>   mutate(sig = p.value < .05) |>   summarise(power = mean(sig)) |>   pull(power)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"study-s2","dir":"Articles","previous_headings":"Reanalyses","what":"Study S2","title":"Calorie Placement Re-Simulation","text":"Now can use pattern Study 1 analyse data Study S2. can even reuse analysis function s1_analyse()!","code":"ss2 <- sim_design(   between = list(placement = c(\"left\", \"right\", \"none\")),   mu = c(1182.15, 1302.23, 1373.74),   sd = c(477.60, 434.41, 475.77),   n = c(139, 141, 151),   dv = \"calories\",   rep = 100 ) ss2_sim <- ss2 |>   mutate(analysis = map(data, s1_analyse)) |>   select(-data) |>   unnest(analysis) ss2_power <- ss2_sim |>   mutate(sig = (p_all < .05) &                 (p_1 < .05) &                 (p_2 < .05)  ) |>   summarise(power = mean(sig)) |>   pull(power)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"study-s3","dir":"Articles","previous_headings":"Reanalyses","what":"Study S3","title":"Calorie Placement Re-Simulation","text":"Now can use pattern Study 1 analyse data Study S3.","code":"ss3 <- sim_design(   between = list(placement = c(\"left\", \"right\", \"none\")),   mu = c(1302.03, 1373.15, 1404.35),   sd = c(480.02, 442.49, 422.03),   n = c(336, 337, 333),   dv = \"calories\",   rep = 100 ) ss3_sim <- ss3 |>   mutate(analysis = map(data, s1_analyse)) |>   select(-data) |>   unnest(analysis) ss3_power <- ss3_sim |>   mutate(sig = (p_all < .05) &                 (p_1 < .05) &                 (p_2 < .05)  ) |>   summarise(power = mean(sig)) |>   pull(power)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/calories.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Calorie Placement Re-Simulation","text":"Now ’ve calculated power 6 studies, just multiply 6 power values together get probability 6 studies significant. reduce() function {purrr} applies function sequentially vector, can give product values power columns. Francis & Thunell paper showed 0.0135577 probability getting 6 6 studies significant. re-simulation showed 0.0130462 probability.","code":"power_table <- tribble(   ~study, ~power_ft, ~ power_my,   \"1\",       0.4582,   s1_power,   \"2\",       0.5426,   s2_power,   \"3\",       0.3626,   s3_power,   \"S1\",      0.5358,  ss1_power,   \"S2\",      0.5667,  ss2_power,   \"S3\",      0.4953,  ss3_power )  power_table ## # A tibble: 6 × 3 ##   study power_ft power_my ##   <chr>    <dbl>    <dbl> ## 1 1        0.458    0.44  ## 2 2        0.543    0.518 ## 3 3        0.363    0.37  ## 4 S1       0.536    0.523 ## 5 S2       0.567    0.58  ## 6 S3       0.495    0.51 prob_ft <- purrr::reduce(power_table$power_ft, `*`) prob_my <- purrr::reduce(power_table$power_my, `*`)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Intro to Faux","text":"’ll using 4 packages tutorial. seed makes randomness reproducible. Run following code several times. Change seed favourite integer. seed , random numbers , long code always executed order.","code":"library(tidyverse) # for data wrangling library(faux)      # for simulation library(broom)     # for tidy analysis results library(afex)      # for ANOVA  set.seed(8675309) # Jenny, I've got your number set.seed(0) rnorm(1) ## [1] 1.262954"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"normal","dir":"Articles","previous_headings":"","what":"Normal","title":"Intro to Faux","text":"Let’s start normal distribution using base R function rnorm(), returns n values normal distribution mean 0 standard deviation 1. can change mean SD. Simulate lot values (1e5 == 100,000), save variable, visualise hist().","code":"rnorm(n = 10) ##  [1] -0.326233361  1.329799263  1.272429321  0.414641434 -1.539950042 ##  [6] -0.928567035 -0.294720447 -0.005767173  2.404653389  0.763593461 x <- rnorm(1e5, mean = 30, sd = 5)  hist(x)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"multivariate-normal","dir":"Articles","previous_headings":"","what":"Multivariate normal","title":"Intro to Faux","text":"create correlated values? can MASS::mvrnorm(), need construct Sigma argument correlation matrix standard deviations populations, need turn resulting matrix data frame many use cases. isn’t difficult, can tedious larger numbers variables.","code":"n = 1e5 # this is a large number to demonstrate that the result is as expected mu = c(A = 1, B = 2, C = 3) sd = c(0.5, 1, 1.5) r = c(0, .25, .5)  cor_mat <- matrix(c(1, r[1], r[2],                      r[1], 1, r[3],                     r[2], r[3], 1),                    nrow = 3) Sigma <- (sd %*% t(sd)) * cor_mat vars <- MASS::mvrnorm(n, mu, Sigma) |> as.data.frame()  cor(vars) |> round(2) ##      A   B    C ## A 1.00 0.0 0.24 ## B 0.00 1.0 0.50 ## C 0.24 0.5 1.00"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"rnorm_multi","dir":"Articles","previous_headings":"Multivariate normal","what":"rnorm_multi","title":"Intro to Faux","text":"faux, can create sets correlated normally distributed values using rnorm_multi(). function get_params() gives quick way see means, SDs correlations simulated data set make sure set parameters correctly. set empirical TRUE, values set sample parameters, population parameters. isn’t usually want simulation, can useful check set parameters correctly.","code":"dat3 <- rnorm_multi(   n = 50,   mu = c(A = 1, B = 2, C = 3),   sd = c(0.5, 1, 1.5),   r = c(0, .25, .5) ) get_params(dat3) ##    n var    A    B    C mean   sd ## 1 50   A 1.00 0.10 0.24 1.10 0.49 ## 2 50   B 0.10 1.00 0.34 2.00 0.86 ## 3 50   C 0.24 0.34 1.00 3.06 1.32 dat3 <- rnorm_multi(   n = 50,   mu = c(A = 1, B = 2, C = 3),   sd = c(0.5, 1, 1.5),   r = c(0, .25, .5),   empirical = TRUE )  get_params(dat3) ##    n var    A   B    C mean  sd ## 1 50   A 1.00 0.0 0.25    1 0.5 ## 2 50   B 0.00 1.0 0.50    2 1.0 ## 3 50   C 0.25 0.5 1.00    3 1.5"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"setting-r","dir":"Articles","previous_headings":"Multivariate normal","what":"Setting r","title":"Intro to Faux","text":"can set r argument correlations different ways. correlations value, just set r equal single number. can set r vector matrix full correlation matrix. convenient ’re getting values existing dataset, can just use output cor() function. Notice , since didn’t specify names 4 variables anywhere else, rnorm_multi() take named correlation matrix. Alternatively, can just specify values upper right triangle correlation matrix. might easier ’re reading values paper.","code":"# all correlations the same value rho_same <- rnorm_multi(50, 4, r = .5, empirical = TRUE) get_params(rho_same) ##    n var  X1  X2  X3  X4 mean sd ## 1 50  X1 1.0 0.5 0.5 0.5    0  1 ## 2 50  X2 0.5 1.0 0.5 0.5    0  1 ## 3 50  X3 0.5 0.5 1.0 0.5    0  1 ## 4 50  X4 0.5 0.5 0.5 1.0    0  1 rho <- cor(iris[1:4]) round(rho, 2) ##              Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length         1.00       -0.12         0.87        0.82 ## Sepal.Width         -0.12        1.00        -0.43       -0.37 ## Petal.Length         0.87       -0.43         1.00        0.96 ## Petal.Width          0.82       -0.37         0.96        1.00 rho_cormat <- rnorm_multi(50, 4, r = rho, empirical = TRUE) get_params(rho_cormat) ##    n          var Sepal.Length Sepal.Width Petal.Length Petal.Width mean sd ## 1 50 Sepal.Length         1.00       -0.12         0.87        0.82    0  1 ## 2 50  Sepal.Width        -0.12        1.00        -0.43       -0.37    0  1 ## 3 50 Petal.Length         0.87       -0.43         1.00        0.96    0  1 ## 4 50  Petal.Width         0.82       -0.37         0.96        1.00    0  1 # upper right triangle #         X2   X3   X4 rho <- c(0.5, 0.4, 0.3, # X1               0.2, 0.1, # X2                    0.0) # X3  rho_urt <- rnorm_multi(50, 4, r = rho, empirical = TRUE) get_params(rho_urt) ##    n var  X1  X2  X3  X4 mean sd ## 1 50  X1 1.0 0.5 0.4 0.3    0  1 ## 2 50  X2 0.5 1.0 0.2 0.1    0  1 ## 3 50  X3 0.4 0.2 1.0 0.0    0  1 ## 4 50  X4 0.3 0.1 0.0 1.0    0  1"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"factorial-designs","dir":"Articles","previous_headings":"","what":"Factorial Designs","title":"Intro to Faux","text":"can use rnorm_multi() simulate data -subjects cell factorial design manually combine tables, faux function better maps onto usually think teach factorial designs. default design 100 observations one variable (named y) mean 0 SD 1. Unless set plot = FALSE run faux_options(plot = FALSE), function show plot design can check looks like expect.","code":"simdat1 <- sim_design()"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"factors","dir":"Articles","previous_headings":"Factorial Designs","what":"Factors","title":"Intro to Faux","text":"Use named lists set names levels within subject factors.  can set mu sd unnamed vectors, getting order right can take trial error.  can set values named vector single type factor. values right order ’re named.  use data frame within- -subject factors.  within-subject factors, set correlations -subject cell like . can also change name dv id columns output data long format. , also need tell get_params() columns contain - within-subject factors, dv, id.","code":"pettime <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\")),   within = list(time = c(\"pre\", \"post\")) ) pettime <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\")),   within = list(time = c(\"pre\", \"post\")),   mu = 1:6 ) pettime <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\")),   within = list(time = c(\"pre\", \"post\")),   mu = c(cat = 1, ferret = 5, dog = 3),   sd = c(pre = 1, post = 2) ) pettime <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\")),   within = list(time = c(\"pre\", \"post\")),   mu = data.frame(     pre = c(1, 3, 5),     post = c(2, 4, 6),     row.names = c(\"cat\", \"dog\", \"ferret\")   ) ) pettime <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\")),   within = list(time = c(\"pre\", \"post\")),   r = list(cat = 0.5,            dog = 0.25,            ferret = 0),   empirical = TRUE,   plot = FALSE )  get_params(pettime) ##      pet   n  var  pre post mean sd ## 1    cat 100  pre 1.00 0.50    0  1 ## 2    cat 100 post 0.50 1.00    0  1 ## 3    dog 100  pre 1.00 0.25    0  1 ## 4    dog 100 post 0.25 1.00    0  1 ## 5 ferret 100  pre 1.00 0.00    0  1 ## 6 ferret 100 post 0.00 1.00    0  1 dat_long <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\")),   within = list(time = c(\"pre\", \"post\")),   id = \"subj_id\",   dv = \"score\",   long = TRUE,   plot = FALSE )  get_params(dat_long, digits = 3) ##      pet   n  var    pre   post   mean    sd ## 1    cat 100  pre  1.000  0.074  0.082 0.944 ## 2    cat 100 post  0.074  1.000  0.097 1.091 ## 3    dog 100  pre  1.000 -0.061  0.036 1.014 ## 4    dog 100 post -0.061  1.000  0.115 1.024 ## 5 ferret 100  pre  1.000  0.009 -0.015 0.998 ## 6 ferret 100 post  0.009  1.000 -0.115 0.887"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"multiple-factors","dir":"Articles","previous_headings":"Factorial Designs","what":"Multiple Factors","title":"Intro to Faux","text":"Set one within--subject factor like :  faux uses underscore separator, set sep argument something different want use underscores variable names (set separator globally faux_options).","code":"dat_multi <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\"),                  country = c(\"UK\", \"NL\")),   within = list(time = c(\"pre\", \"post\"),                 condition = c(\"ctl\", \"exp\")),   mu = data.frame(     cat_UK = 1:4,     cat_NL = 5:8,     dog_UK = 9:12,     dog_NL = 13:16,     ferret_UK = 17:20,      ferret_NL = 21:24,     row.names = c(\"pre_ctl\", \"pre_exp\", \"post_ctl\", \"post_exp\")   ) ) # faux_options(sep = \".\")  dat_multi <- sim_design(   between = list(pet = c(\"cat\", \"dog\", \"ferret\"),                  country = c(\"Glasgow_UK\", \"Rotterdam_NL\")),   within = list(time = c(\"pre\", \"post\"),                 condition = c(\"ctl\", \"exp\")),   mu = data.frame(     cat.Glasgow_UK = 1:4,     cat.Rotterdam_NL = 5:8,     dog.Glasgow_UK = 9:12,     dog.Rotterdam_NL = 13:16,     ferret.Glasgow_UK = 17:20,      ferret.Rotterdam_NL = 21:24,     row.names = c(\"pre.ctl\", \"pre.exp\", \"post.ctl\", \"post.exp\")   ),   sep = \".\" )"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"anonymous-factors","dir":"Articles","previous_headings":"Factorial Designs","what":"Anonymous Factors","title":"Intro to Faux","text":"need make quick demo, can set factors anonymously integer vectors. example, following code makes 3B*2B*2W mixed design.  Faux quick plotting function visualising data made faux. plot created sim_design() shows design, function shows simulated data.  can change order plotting types geoms plotted. takes little trial error, function probably refined later versions.","code":"dat_anon <- sim_design(   n = 50,   between = c(3, 2),   within = 2,   mu = 1:12 ) plot(dat_anon) plot(dat_anon, \"B1\", \"B2\", \"W1\", geoms = c(\"violin\", \"pointrangeSD\"))"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"replications","dir":"Articles","previous_headings":"","what":"Replications","title":"Intro to Faux","text":"often want simulate data repeatedly things like calculate power. sim_design() function lot overhead checking design makes sense correlation matrix possible, can speed creation multiple datasets design using rep argument. give nested data frame dataset data column.","code":"dat_rep <- sim_design(   within = 2,   n = 20,   mu = c(0, 0.25),   rep = 5,   plot = FALSE )"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"analyse-each-replicate","dir":"Articles","previous_headings":"Replications","what":"Analyse each replicate","title":"Intro to Faux","text":"can run analyses nested data wrapping analysis code function using map() run analysis data set unnest() expand results data table.","code":"# define function analyse <- function(data) {   t.test(data$W1a, data$W1b, paired = TRUE) %>% broom::tidy() }  # get one test data set data <- dat_rep$data[[1]]  # check function returns what you want analyse(data) ## # A tibble: 1 × 8 ##   estimate statistic p.value parameter conf.low conf.high method     alternative ##      <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>      <chr>       ## 1   -0.528     -1.96  0.0647        19    -1.09    0.0354 Paired t-… two.sided # run the function on each data set dat_rep |>   mutate(analysis = map(data, analyse)) |>   select(-data) |>   unnest(analysis) ## # A tibble: 5 × 9 ##     rep estimate statistic p.value parameter conf.low conf.high method        ##   <int>    <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>         ## 1     1  -0.528    -1.96    0.0647        19   -1.09     0.0354 Paired t-test ## 2     2  -0.532    -2.68    0.0147        19   -0.947   -0.117  Paired t-test ## 3     3   0.0199    0.0701  0.945         19   -0.576    0.616  Paired t-test ## 4     4  -0.111    -0.311   0.759         19   -0.856    0.635  Paired t-test ## 5     5  -0.856    -2.02    0.0576        19   -1.74     0.0305 Paired t-test ## # ℹ 1 more variable: alternative <chr>"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"anova","dir":"Articles","previous_headings":"Replications","what":"ANOVA","title":"Intro to Faux","text":"Use pattern run ANOVA version pettime dataset. First, simulate 100 datasets long format. data small main effects pet time, interaction.  set analysis. ’ll use aov_ez() function {afex} package arguments match sim_design(). ’s little setup run first get rid annoying messages make run faster omitting calculations won’t need. custom function takes data frame input runs ANOVA . code end just cleans resulting table bit. Test analysis code first simulated data frame. Use code used first example make table results analysis: can summarise data calculate things like power effect mean effect size. power -subjects effect pet smaller within-subjects effect time. happens reduce correlation pre post?","code":"pettime100 <- sim_design(   between = list(pet = c(\"cat\", \"dog\")),   within = list(time = c(\"pre\", \"post\")),   n = c(cat = 50, dog = 40),   mu = data.frame(     pre = c(1, 1.2),     post = c(1.2, 1.4),     row.names = c(\"cat\", \"dog\")   ),   sd = 1,   id = \"pet_id\",   dv = \"score\",   r = 0.5,   long = TRUE,   rep = 100 ) afex::set_sum_contrasts() # avoids annoying afex message ## setting contr.sum globally: options(contrasts=c('contr.sum', 'contr.poly')) afex_options(include_aov = FALSE) # runs faster afex_options(es_aov = \"pes\") # changes effect size measure to partial eta squared analyse <- function(data) {   a <- afex::aov_ez(     id = \"pet_id\",     dv = \"score\",     between = \"pet\",     within = \"time\",     data = data   )    # return anova_table for GG-corrected DF   as_tibble(a$anova_table, rownames = \"term\") |>     mutate(term = factor(term, levels = term)) |> # keeps terms in order     rename(p.value = `Pr(>F)`) # fixes annoying p.value name } analyse( pettime100$data[[1]] ) ## # A tibble: 3 × 7 ##   term     `num Df` `den Df`   MSE     F     pes p.value ##   <fct>       <dbl>    <dbl> <dbl> <dbl>   <dbl>   <dbl> ## 1 pet             1       88 1.42  0.693 0.00781  0.408  ## 2 time            1       88 0.466 4.76  0.0513   0.0318 ## 3 pet:time        1       88 0.466 0.166 0.00189  0.684 pettime_sim <- pettime100 |>   mutate(analysis = map(data, analyse)) |>   select(-data) |>   unnest(analysis) ## # A tibble: 6 × 8 ##     rep term     `num Df` `den Df`   MSE     F   pes p.value ##   <int> <fct>       <dbl>    <dbl> <dbl> <dbl> <dbl>   <dbl> ## 1     1 pet             1       88 1.42  0.693 0.008   0.408 ## 2     1 time            1       88 0.466 4.76  0.051   0.032 ## 3     1 pet:time        1       88 0.466 0.166 0.002   0.684 ## 4     2 pet             1       88 1.94  4.32  0.047   0.04  ## 5     2 time            1       88 0.506 1.86  0.021   0.177 ## 6     2 pet:time        1       88 0.506 1.49  0.017   0.225 pettime_sim |>   group_by(term) |>   summarise(power = mean(p.value < 0.05),             mean_pes = mean(pes) |> round(3),             .groups = \"drop\") ## # A tibble: 3 × 3 ##   term     power mean_pes ##   <fct>    <dbl>    <dbl> ## 1 pet       0.2     0.024 ## 2 time      0.45    0.05  ## 3 pet:time  0.04    0.01"},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"non-normal-distributions","dir":"Articles","previous_headings":"","what":"Non-normal Distributions","title":"Intro to Faux","text":"newest version faux new function simulating non-normal distributions using NORTA method (NORmal Anything). dist argument lists variables distribution names (e.g., “norm”, “pois”, unif”, “truncnorm”, anything “rdist” function). params argument lists distribution function argument values variable (e.g., arguments rnorm, rpois, runif, rtruncnorm). function simulates multivariate non-normal distributions using simulation work correlations multivariate normal distribution produce desired correlations normal distributions converted desired distributions. simulation can take several variables warn ’re requesting impossible combination (still experimental function, let Lisa know problems). “likert” type set distribution functions provided faux make creating Likert scale variables easier (see ?rlikert). may need convert Likert-scale variables numbers analysis calculating descriptives.","code":"dat_norta <- rmulti(   n = 1000,   dist = c(U = \"unif\",            T = \"truncnorm\",            L = \"likert\"),   params = list(     U = list(min = 0, max = 10),     T = list(a = 1, b = 7, mean = 3.5, sd = 2.1),     L = list(prob = c(`much less` = .10,                        `less`      = .20,                        `equal`     = .35,                        `more`      = .25,                        `much more` = .10))   ),   r = c(-0.5, 0, 0.5) ) # convert likert-scale variable to integer dat_norta$L <- as.integer(dat_norta$L)  get_params(dat_norta) ##      n var     U     T     L mean   sd ## 1 1000   U  1.00 -0.46 -0.01 4.98 2.88 ## 2 1000   T -0.46  1.00  0.52 3.67 1.46 ## 3 1000   L -0.01  0.52  1.00 3.02 1.11"},{"path":[]},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"multivariate-normal-1","dir":"Articles","previous_headings":"Exercises","what":"Multivariate normal","title":"Intro to Faux","text":"Sample 40 values three variables named J, K L population means 10, 20 30, SDs 5. J K correlated 0.5, J L correlated 0.25, K L correlated.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"from-existing-data","dir":"Articles","previous_headings":"Exercises","what":"From existing data","title":"Intro to Faux","text":"Using data built-dataset attitude, simulate new set 20 observations drawn population means, SDs correlations column original data.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"b","dir":"Articles","previous_headings":"Exercises","what":"2b","title":"Intro to Faux","text":"Create dataset -subject factor “pet” two levels, “cat”, “dog”. DV “happiness” score. 20 cat-owners mean happiness score 10 (SD = 3) 30 dog-owners mean happiness score 11 (SD = 3).","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"w","dir":"Articles","previous_headings":"Exercises","what":"3w","title":"Intro to Faux","text":"Create dataset 20 observations 1 within-subject variable (“condition”) 3 levels (“”, “B”, “C”) means 10, 20 30 SD 5. correlations level r = 0.4. dataset look like :","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"w2w","dir":"Articles","previous_headings":"Exercises","what":"2w*2w","title":"Intro to Faux","text":"Create dataset 50 subjects 2 within-subject variables (“W1” “W2”) 2 levels. mean cells 10 SD 2. correlations look like :","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"w3b","dir":"Articles","previous_headings":"Exercises","what":"2w*3b","title":"Intro to Faux","text":"Create dataset -subject factor “pet” 3 levels (“cat”, “dog”, “ferret”) within-subject factor “time” 2 levels (“pre” “post”). N group 10. Means : cats: pre = 10, post = 12 dogs: pre = 14, post = 16 ferrets: pre = 18, post = 20 SDs 5 within-cell correlations 0.25.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"replications-1","dir":"Articles","previous_headings":"Exercises","what":"Replications","title":"Intro to Faux","text":"Create 5 datasets 2b*2b design, 30 participants cell. cell’s mean 0, except B1a:B2a, 0.5. SD 1. Make resulting data long format.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/faux.html","id":"power","dir":"Articles","previous_headings":"Exercises","what":"Power","title":"Intro to Faux","text":"Simulate 100 datasets like one use lm() afex::aov_ez() look interaction B. power design?","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"simulation-functions","dir":"Articles","previous_headings":"","what":"Simulation functions","title":"Fixed Effects","text":"functions commonly used ’re setting simulated dataset.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"repeating","dir":"Articles","previous_headings":"Simulation functions","what":"Repeating","title":"Fixed Effects","text":"function rep() lets repeat first argument number times. Use rep() create vector alternating \"\" \"B\" values length 24. second argument vector length first argument, element first vector repeated many times. Use rep() create vector 11 \"\" values followed 3 \"B\" values. can repeat element vector specified number times using argument, Use rep() create vector 12 \"\" values followed 12 \"B\" values. think happen set times 3 2?","code":"rep(c(\"A\", \"B\"), times = 12) ##  [1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" ## [20] \"B\" \"A\" \"B\" \"A\" \"B\" rep(c(\"A\", \"B\"), c(11, 3)) ##  [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\" rep(c(\"A\", \"B\"), each = 12) ##  [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" ## [20] \"B\" \"B\" \"B\" \"B\" \"B\" rep(c(\"A\", \"B\"), times = 3, each = 2) ##  [1] \"A\" \"A\" \"B\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\" \"A\" \"B\" \"B\""},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"sequences","dir":"Articles","previous_headings":"Simulation functions","what":"Sequences","title":"Fixed Effects","text":"function seq() useful generating sequence numbers pattern. Use seq() create vector integers 0 10. can set argument count numbers 1 (default). Use seq() create vector numbers 0 100 10s. argument length.useful know many steps want divide something . Use seq() create vector starts 0, ends 100, 12 equally spaced steps (hint: many numbers vector 2 steps?).","code":"seq(0, 10) ##  [1]  0  1  2  3  4  5  6  7  8  9 10 seq(0, 100, by = 10) ##  [1]   0  10  20  30  40  50  60  70  80  90 100 seq(0, 100, length.out = 13) ##  [1]   0.000000   8.333333  16.666667  25.000000  33.333333  41.666667 ##  [7]  50.000000  58.333333  66.666667  75.000000  83.333333  91.666667 ## [13] 100.000000"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"uniform-distribution","dir":"Articles","previous_headings":"Simulation functions","what":"Uniform Distribution","title":"Fixed Effects","text":"uniform distribution simplest distribution. numbers range equal probability sampled. Use runif() sample continuous uniform distribution. Pipe result hist() make quick histogram simulated data.","code":"runif(n = 10, min = 0, max = 1) ##  [1] 0.1594836 0.4781883 0.7647987 0.7696877 0.2685485 0.6730459 0.9787908 ##  [8] 0.8463270 0.8566562 0.4451601 runif(100000, min = 0, max = 1) %>% hist()"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"discrete-distribution","dir":"Articles","previous_headings":"Simulation functions","what":"Discrete Distribution","title":"Fixed Effects","text":"can use sample() simulate events like rolling dice choosing deck cards. code simulates rolling 6-sided die 10000 times. set replace TRUE event independent. See happens set replace FALSE. Distribution dice rolls. can also use sample sample list named outcomes. Ferrets, best pet, much less common pet cats dogs, sample isn’t realistic. can set probabilities item list prob argument.","code":"rolls <- sample(1:6, 10000, replace = TRUE)  # plot the results as.factor(rolls) %>% plot() pet_types <- c(\"cat\", \"dog\", \"ferret\", \"bird\", \"fish\") sample(pet_types, 10, replace = TRUE) ##  [1] \"dog\"    \"fish\"   \"cat\"    \"fish\"   \"bird\"   \"bird\"   \"fish\"   \"ferret\" ##  [9] \"ferret\" \"bird\" pet_types <- c(\"cat\", \"dog\", \"ferret\", \"bird\", \"fish\") pet_prob <- c(0.3, 0.4, 0.1, 0.1, 0.1) pet_data <- sample(pet_types, 100, replace = TRUE, prob = pet_prob)   as.factor(pet_data) %>% plot()"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"binomial-distribution","dir":"Articles","previous_headings":"Simulation functions","what":"Binomial Distribution","title":"Fixed Effects","text":"rbinom function generate random binomial distribution. n = number observations size = number trials prob = probability success trial Coin flips typical example binomial distribution, can assign heads 1 tails 0. can generate total number heads 1 set 20 coin flips setting size 20 n 1. can generate sets 20 coin flips increasing n.","code":"# 20 individual coin flips of a fair coin rbinom(20, 1, 0.5) ##  [1] 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 # 20 individual coin flips of a baised (0.75) coin rbinom(20, 1, 0.75) ##  [1] 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 # 1 set of 20 fair coin flips rbinom(1, 20, 0.75) ## [1] 13 # 10 sets of 20 fair coin flips rbinom(10, 20, 0.5) ##  [1] 12  7 10 11 11  8 11  7 12  8"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"normal-distribution","dir":"Articles","previous_headings":"Simulation functions","what":"Normal Distribution","title":"Fixed Effects","text":"can simulate normal distribution size n know mean standard deviation (sd). density plot usually best way visualise type data.  Run simulation several times, noting density plot changes. Try changing values n, mean, sd.","code":"# 10 samples from a normal distribution with a mean of 0 and SD of 1 rnorm(10, 0, 1) ##  [1] -0.3230057  0.7213149  0.4248971  1.4033239 -0.6881243 -0.2737261 ##  [7] -0.1539815 -0.3908546 -0.3301087  1.7890306 # 100 samples from a normal distribution with a mean of 10 and SD of 2 dv <- rnorm(100, 10, 2)  # use sample to get a random colour fill_colour <- sample(colours(), 1)  ggplot() +   geom_density(aes(dv), fill = fill_colour) +   scale_x_continuous(     limits = c(0,20),      breaks = seq(0,20)   )"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"independent-samples","dir":"Articles","previous_headings":"","what":"Independent samples","title":"Fixed Effects","text":"Now ’re ready start simulating data. Let’s start simple independent-samples design variables normal distribution. subject produces one score (condition B). need know scores : many subjects condition? score means? score variances (SDs)?","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"parameters","dir":"Articles","previous_headings":"Independent samples","what":"Parameters","title":"Fixed Effects","text":"First, set parameters values. way, can use variables wherever need rest code can easily change .","code":"A_sub_n <- 50 B_sub_n <- 50 A_mean  <- 10 B_mean  <- 11 A_sd    <- 2.5 B_sd    <- 2.5"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"scores","dir":"Articles","previous_headings":"Independent samples","what":"Scores","title":"Fixed Effects","text":"can generate scores using rnorm() function. can stop just analyse simulated data t.test(A_scores, B_scores), usually want get simulated data data table looks like might eventually import CSV file actual experimental data. ’re simulating data script eventually import data csv file, can save data csv file re-read , get real data, need comment simulation steps.","code":"A_scores <- rnorm(A_sub_n, A_mean, A_sd) B_scores <- rnorm(B_sub_n, B_mean, B_sd) dat <- tibble(   sub_condition = rep( c(\"A\", \"B\"), c(A_sub_n, B_sub_n) ),   score = c(A_scores, B_scores) ) # make a data directory if there isn't one already if (!dir.exists(\"data\")) dir.create(\"data\")  # save your simulated data write_csv(dat, \"data/sim-data-ind-samples.csv\")  # start your analysis here dat <- read_csv(\"data/sim-data-ind-samples.csv\") ## Rows: 100 Columns: 2 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \",\" ## chr (1): sub_condition ## dbl (1): score ##  ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"check-your-data","dir":"Articles","previous_headings":"Independent samples","what":"Check your data","title":"Fixed Effects","text":"Always examine simulated data generate make sure looks like want.","code":"dat %>%   group_by(sub_condition) %>%   summarise(n = n() ,             mean = mean(score),             sd = sd(score),             .groups = \"drop\") ## # A tibble: 2 × 4 ##   sub_condition     n  mean    sd ##   <chr>         <int> <dbl> <dbl> ## 1 A                50  10.3  2.54 ## 2 B                50  10.8  2.38"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"analysis","dir":"Articles","previous_headings":"Independent samples","what":"Analysis","title":"Fixed Effects","text":"","code":"t.test(score~sub_condition, dat) ##  ##  Welch Two Sample t-test ##  ## data:  score by sub_condition ## t = -0.99215, df = 97.577, p-value = 0.3236 ## alternative hypothesis: true difference in means between group A and group B is not equal to 0 ## 95 percent confidence interval: ##  -1.4645314  0.4882661 ## sample estimates: ## mean in group A mean in group B  ##        10.31599        10.80412"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"function","dir":"Articles","previous_headings":"Independent samples","what":"Function","title":"Fixed Effects","text":"can wrap function can run many times power calculation. Put parameters arguments function. Now run new function values used . Now can use function run many simulations. function map_df purrr package (loaded tidyverse) one many ways run function many times organise results table. Now can graph data simulations.  Distribution results simulated independent samples data can calculate power proportion simulations p-value less alpha.","code":"ind_sim <- function(A_sub_n, B_sub_n,                      A_mean, B_mean,                      A_sd, B_sd) {   # simulate data for groups A and B   A_scores <- rnorm(A_sub_n, A_mean, A_sd)   B_scores <- rnorm(B_sub_n, B_mean, B_sd)      # put the data into a table   dat <- tibble(     sub_condition = rep( c(\"A\", \"B\"), c(A_sub_n, B_sub_n) ),     score = c(A_scores, B_scores)   )      # analyse the data   t <- t.test(score~sub_condition, dat)      # return a list of the values you care about   # the double brackets ([[]]) get rid of the name of named numbers   list(     t = t$statistic[[1]],     ci_lower = t$conf.int[[1]],     ci_upper = t$conf.int[[2]],     p = t$p.value[[1]],     estimate = t$estimate[[1]] - t$estimate[[2]]   ) } # str() prints the resulting list in a shorter format ind_sim(50, 50, 10, 11, 2.5, 2.5) %>% str() ## List of 5 ##  $ t       : num -2.18 ##  $ ci_lower: num -2.11 ##  $ ci_upper: num -0.101 ##  $ p       : num 0.0314 ##  $ estimate: num -1.1 mysim <- map_df(1:1000, ~ind_sim(50, 50, 10, 11, 2.5, 2.5)) # set boundary = 0 when plotting p-values ggplot(mysim, aes(p)) +   geom_histogram(binwidth = 0.05, boundary = 0,                  fill = \"white\", colour = \"black\") mysim %>%   gather(stat, value, t:estimate) %>%   ggplot() +    geom_density(aes(value, color = stat), show.legend = FALSE) +   facet_wrap(~stat, scales = \"free\") alpha <- 0.05 power <- mean(mysim$p < alpha) power ## [1] 0.474"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"paired-samples","dir":"Articles","previous_headings":"","what":"Paired samples","title":"Fixed Effects","text":"Now let’s try paired-samples design variables normal distribution. subject produces two scores (conditions B). need know two scores : many subjects? score means? score variances (SDs)? correlation scores?","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"paired-params","dir":"Articles","previous_headings":"Paired samples","what":"Parameters","title":"Fixed Effects","text":"","code":"sub_n <- 100 A_mean <- 10 B_mean <- 11 A_sd <- 2.5 B_sd <- 2.5 AB_r <- 0.5"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"correlated-scores","dir":"Articles","previous_headings":"Paired samples","what":"Correlated Scores","title":"Fixed Effects","text":"can use rnorm_multi() generate data table simulated values correlated scores: can also using MASS::mvrnorm function, faux::rnorm_multi easier variables simulate.","code":"dat <- faux::rnorm_multi(     n = sub_n,      vars = 2,      r = AB_r,      mu = c(A_mean, B_mean),      sd = c(A_sd, B_sd),      varnames = c(\"A\", \"B\")   ) # make the correlation matrix cormat <- matrix(c(   1, AB_r,                    AB_r,    1),               nrow = 2, byrow = TRUE)  # make a corresponding matrix of the variance  # (multiply the SDs for each cell) varmat <- matrix(c(A_sd * A_sd, A_sd * B_sd,                    A_sd * B_sd, B_sd * B_sd),               nrow = 2, byrow = TRUE)   # create correlated variables with the specified parameters S <- MASS::mvrnorm(n = sub_n,                     mu = c(A_mean, B_mean),                     Sigma = cormat * varmat) dat <- data.frame(   A = S[, 1],   B = S[, 2] )"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"check-your-data-1","dir":"Articles","previous_headings":"Paired samples","what":"Check your data","title":"Fixed Effects","text":"Now check data; faux function get_params() gives correlation table, means, SDs numeric column data table.","code":"faux::get_params(dat) ##     n var    A    B  mean   sd ## 1 100   A 1.00 0.49 10.09 2.57 ## 2 100   B 0.49 1.00 11.27 2.50"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"analysis-1","dir":"Articles","previous_headings":"Paired samples","what":"Analysis","title":"Fixed Effects","text":"","code":"# paired-samples t-test t.test(dat$A, dat$B, paired = TRUE) ##  ##  Paired t-test ##  ## data:  dat$A and dat$B ## t = -4.6022, df = 99, p-value = 1.242e-05 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ##  -1.6843022 -0.6694754 ## sample estimates: ## mean difference  ##       -1.176889"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"function-1","dir":"Articles","previous_headings":"Paired samples","what":"Function","title":"Fixed Effects","text":"Run 1000 simulations graph results. Distribution results simulated paired samples data","code":"paired_sim <- function(sub_n, A_mean, B_mean, A_sd, B_sd, AB_r) {    dat <- faux::rnorm_multi(     n = sub_n,      vars = 2,      r = AB_r,      mu = c(A_mean, B_mean),      sd = c(A_sd, B_sd),      varnames = c(\"A\", \"B\")   )   t <- t.test(dat$A, dat$B, paired = TRUE)      # return just the values you care about   list(     t = t$statistic[[1]],     ci_lower = t$conf.int[[1]],     ci_upper = t$conf.int[[2]],     p = t$p.value[[1]],     estimate = t$estimate[[1]]   ) } mysim_p <- map_df(1:1000, ~paired_sim(100, 10, 11, 2.5, 2.5, .5)) mysim_p %>%   gather(stat, value, t:estimate) %>%   ggplot() +    geom_density(aes(value, color = stat), show.legend = FALSE) +   facet_wrap(~stat, scales = \"free\") alpha <- 0.05 power <- mean(mysim_p$p < alpha) power ## [1] 0.983"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"intercept-model","dir":"Articles","previous_headings":"","what":"Intercept model","title":"Fixed Effects","text":"Now ’m going show different way simulate design. might seem excessively complicated, need pattern start simulating data mixed effects models.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"parameters-1","dir":"Articles","previous_headings":"Intercept model","what":"Parameters","title":"Fixed Effects","text":"Remember, used following parameters set simulation : , can calculate grand intercept (overall mean regardless condition), effect condition (mean B minus ). also need think variance little differently. First, calculate pooled variance mean variances B (remember, variance SD squared). variance subject intercepts r times pooled variance error variance left . take square root (sqrt()) set subject intercept error SDs simulation later.","code":"sub_n  <- 100 A_mean <- 10 B_mean <- 11 A_sd   <- 2.5 B_sd   <- 2.5 AB_r   <- 0.5 grand_i   <- (A_mean + B_mean)/2 AB_effect <- B_mean - A_mean pooled_var <- (A_sd^2 + B_sd^2)/2 sub_sd   <- sqrt(pooled_var * AB_r) error_sd <- sqrt(pooled_var * (1-AB_r))"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"subject-intercepts","dir":"Articles","previous_headings":"Intercept model","what":"Subject intercepts","title":"Fixed Effects","text":"Now use variables create data table subjects. subject gets ID random intercept (sub_i). intercept simulated random normal distribution mean 0 SD sub_sd. represents much higher lower average score subject tends (regardless condition).","code":"sub <- tibble(   sub_id = 1:sub_n,   sub_i = rnorm(sub_n, 0, sub_sd) )"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"observations","dir":"Articles","previous_headings":"Intercept model","what":"Observations","title":"Fixed Effects","text":"Next, set table row represents one observation. ’ll use one favourite functions simulation: crossing(). creates every possible combination listed factors (works expand.grid(), results intuitive order). , ’re using create row subject condition, since fully within-subjects design.","code":"obs <- crossing(   sub_id = 1:sub_n,   condition = c(\"A\", \"B\") )"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"calculate-the-score","dir":"Articles","previous_headings":"Intercept model","what":"Calculate the score","title":"Fixed Effects","text":"Next, join subject table row information subject’s random intercept calculate score. ’ve done steps clarity. score just sum : overall mean (grand_i) subject-specific intercept (sub_i) effect (effect): numeric code condition (condition.e) multiplied effect condition (AB_effect) error term (simulated normal distribution mean 0 SD error_sd) Use get_params check data. data long format, need specify columns contain id, dv, within-id variables. can use following code put data table familiar “wide” format.","code":"dat <- obs %>%   left_join(sub, by = \"sub_id\") %>%   mutate(     condition.e = recode(condition, \"A\" = -0.5, \"B\" = 0.5),     effect = AB_effect * condition.e,     error = rnorm(nrow(.), 0, error_sd),     score = grand_i + sub_i + effect + error   ) # check the data faux::get_params(dat,                   id = \"sub_id\",                  dv = \"score\",                  within = \"condition\") ##     n var    A    B  mean   sd ## 1 100   A 1.00 0.59  9.68 2.40 ## 2 100   B 0.59 1.00 10.33 2.58 dat_wide <- dat %>%   select(sub_id, condition, score) %>%   spread(condition, score)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"analyses","dir":"Articles","previous_headings":"Intercept model","what":"Analyses","title":"Fixed Effects","text":"can analyse data paired-samples t-test wide format: long format: can analyse data ANOVA using aov_4() function afex. (Notice F-value square t-value .) can even analyse data mixed effects model using lmer function (afex version gives p-values, lme4 version ).","code":"# paired-samples t-test from dat_wide t.test(dat_wide$A, dat_wide$B, paired = TRUE) ##  ##  Paired t-test ##  ## data:  dat_wide$A and dat_wide$B ## t = -2.8648, df = 99, p-value = 0.005095 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ##  -1.0923496 -0.1983759 ## sample estimates: ## mean difference  ##      -0.6453628 # paired-samples t-test from dat (long) t.test(score ~ condition, dat, paired = TRUE) ##  ##  Paired t-test ##  ## data:  score by condition ## t = -2.8648, df = 99, p-value = 0.005095 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ##  -1.0923496 -0.1983759 ## sample estimates: ## mean difference  ##      -0.6453628 # anova using afex::aov_4 aov <- afex::aov_4(score ~ (condition | sub_id), data = dat)  aov$anova_table ## Anova Table (Type 3 tests) ##  ## Response: score ##           num Df den Df    MSE      F      ges   Pr(>F)    ## condition      1     99 2.5373 8.2072 0.016676 0.005095 ** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 # mixed effect model using afex::lmer lmem <- afex::lmer(score ~ condition.e + (1 | sub_id), data = dat)  # displays a tidy table of the fixed effects broom.mixed::tidy(lmem, effects = \"fixed\") ## # A tibble: 2 × 7 ##   effect term        estimate std.error statistic    df  p.value ##   <chr>  <chr>          <dbl>     <dbl>     <dbl> <dbl>    <dbl> ## 1 fixed  (Intercept)   10.0       0.222     45.0   99.0 9.08e-68 ## 2 fixed  condition.e    0.645     0.225      2.86  99.0 5.10e- 3"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"simulate-a-dataset-from-an-analysis","dir":"Articles","previous_headings":"","what":"Simulate a dataset from an analysis","title":"Fixed Effects","text":"Simulate dataset parameters analysis. ’ll use built-dataset mtcars predict miles per gallon (mpg) transmission type () engine type (vs).","code":"model <- lm(mpg ~ am * vs, data = mtcars) broom::tidy(model) ## # A tibble: 4 × 5 ##   term        estimate std.error statistic  p.value ##   <chr>          <dbl>     <dbl>     <dbl>    <dbl> ## 1 (Intercept)    15.0       1.00     15.0  6.34e-15 ## 2 am              4.70      1.74      2.71 1.14e- 2 ## 3 vs              5.69      1.65      3.45 1.80e- 3 ## 4 am:vs           2.93      2.54      1.15 2.59e- 1"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"simulate","dir":"Articles","previous_headings":"Simulate a dataset from an analysis","what":"Simulate","title":"Fixed Effects","text":"can now simulate dataset 50 observations transmission type () engine type (vs) combination, use model parameters generate predicted values mpg. Analyse simulated data lm() output results table using broom::tidy()","code":"err_sd <- sigma(model) # SD of the error term from the model fx <- coefficients(model) # fixed effect coefficients  sim_mtcars <- tibble(   am = rep(c(0, 0, 1, 1), each = 50),   vs = rep(c(0, 1, 0, 1), each = 50) ) %>%   mutate(err = rnorm(200, 0, err_sd),          mpg = fx[1] +                 fx[\"am\"]*am +                 fx[\"vs\"]*vs +                fx[\"am:vs\"]*am*vs + err) sim_model <- lm(mpg ~ am * vs, data = sim_mtcars) broom::tidy(sim_model) ## # A tibble: 4 × 5 ##   term        estimate std.error statistic  p.value ##   <chr>          <dbl>     <dbl>     <dbl>    <dbl> ## 1 (Intercept)    14.8      0.523     28.3  3.18e-71 ## 2 am              5.61     0.739      7.60 1.21e-12 ## 3 vs              6.62     0.739      8.95 2.67e-16 ## 4 am:vs           1.96     1.05       1.87 6.24e- 2"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"function-2","dir":"Articles","previous_headings":"Simulate a dataset from an analysis","what":"Function","title":"Fixed Effects","text":"Run function values original model, cut fixed effect sizes half. Repeat 100 time calculate power effect.","code":"carsim <- function(n, b0, b_am, b_vs, b_am_vs, err_sd) {   sim_mtcars <- tibble(     am = rep(c(0, 0, 1, 1), each = n),     vs = rep(c(0, 1, 0, 1), each = n)   ) %>%     mutate(err = rnorm(n*4, 0, err_sd),            mpg = b0 + b_am*am + b_vs*vs + b_am_vs*am*vs + err)      sim_model <- lm(mpg ~ am * vs, data = sim_mtcars)   broom::tidy(sim_model) } err_sd <- sigma(model) fx2 <- coefficients(model)/2  carsim(50, fx2[1], fx2[2], fx2[3], fx2[4], err_sd) ## # A tibble: 4 × 5 ##   term        estimate std.error statistic  p.value ##   <chr>          <dbl>     <dbl>     <dbl>    <dbl> ## 1 (Intercept)    7.25      0.535    13.5   6.06e-30 ## 2 am             2.78      0.757     3.67  3.11e- 4 ## 3 vs             3.97      0.757     5.25  3.95e- 7 ## 4 am:vs         -0.200     1.07     -0.187 8.52e- 1 simstats <- map_df(1:100, ~carsim(50, fx2[1], fx2[2], fx2[3], fx2[4], err_sd))  simstats %>%   group_by(term) %>%   summarise(power = mean(p.value < .05), .groups = \"drop\") ## # A tibble: 4 × 2 ##   term        power ##   <chr>       <dbl> ## 1 (Intercept)  1    ## 2 am           0.92 ## 3 am:vs        0.3  ## 4 vs           0.96"},{"path":"https://debruine.github.io/data-sim-workshops/articles/fixed.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Fixed Effects","text":"Using dataset , predict moral disgust interaction pathogen sexual disgust using lm(). Simulate new dataset 100 people similar pathogen sexual disgust distribution original dataset. Remember likely correlated scores can range 0 6. (Hint: look help norm2trunc) Write function simulate data, analyse , return table results. Make sure can vary important parameters using arguments. Calculate power fixed effects original analysis. Adjust N dsign around .80 power detect main effect pathogen disgust.","code":"disgust <- read_csv(\"https://psyteachr.github.io/msc-data-skills/data/disgust_scores.csv\") ## Rows: 20000 Columns: 6 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \",\" ## dbl  (5): id, user_id, moral, pathogen, sexual ## date (1): date ##  ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Mixed Effects","text":"","code":"library(tidyverse)   # for data wrangling, pipes, and good dataviz library(afex)        # for mixed effect models library(broom.mixed) # for getting tidy data tables from mixed models library(faux)        # for simulating correlated variables  options(digits = 4, scipen = 10)"},{"path":[]},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"random-factors","dir":"Articles","previous_headings":"Simulation","what":"Random Factors","title":"Mixed Effects","text":"First, set overall structure data specifying number observations random factor. , crossed design, subject responds stimulus. ’ll set numbers small numbers demo first.","code":"sub_n  <- 2 # number of subjects in this simulation stim_n  <- 2 # number of stimuli in this simulation  dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n)  dat ## # A tibble: 4 × 2 ##   sub   stim  ##   <chr> <chr> ## 1 sub1  stim1 ## 2 sub1  stim2 ## 3 sub2  stim1 ## 4 sub2  stim2"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"fixed-factors","dir":"Articles","previous_headings":"Simulation","what":"Fixed Factors","title":"Mixed Effects","text":"Next, add fixed factors. Specify vary one random factors specify names levels. subject one condition, code assigns half easy half hard. can change proportion subjects assigned level .prob argument. Stimuli seen congruent incongruent versions, double number rows resulting data set.","code":"sub_n  <- 2 # number of subjects in this simulation stim_n  <- 2 # number of stimuli in this simulation  dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n) |>   add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>   add_within(version = c(\"congruent\", \"incongruent\"))  dat ## # A tibble: 8 × 4 ##   sub   stim  condition version     ##   <chr> <chr> <fct>     <fct>       ## 1 sub1  stim1 easy      congruent   ## 2 sub1  stim1 easy      incongruent ## 3 sub1  stim2 easy      congruent   ## 4 sub1  stim2 easy      incongruent ## 5 sub2  stim1 hard      congruent   ## 6 sub2  stim1 hard      incongruent ## 7 sub2  stim2 hard      congruent   ## 8 sub2  stim2 hard      incongruent"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"contrast-coding","dir":"Articles","previous_headings":"Simulation","what":"Contrast Coding","title":"Mixed Effects","text":"able calculate dependent variable, need recode categorical variables numbers. Use helper function add_contrast() . code creates anova-coded versions condition version. Luckily us, factor levels default sensible order, “easy” predicted faster (lower) reactive time “hard”, “congruent” predicted faster RT “incongruent”, can also customise order levels add_contrast(); see contrasts vignette details. function defaults descriptive names help interpret fixed factors. , “condition.hard-easy” means main effect factor interpreted RT hard trials minus RT easy trials, “version.incongruent-congruent” means main effect factor interpreted RT incongruent trials minus RT congruent trials. However, can change simpler labels colnames argument.","code":"sub_n  <- 2 # number of subjects in this simulation stim_n  <- 2 # number of stimuli in this simulation  dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n) |>   add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>   add_within(version = c(\"congruent\", \"incongruent\")) |>   add_contrast(\"condition\") |>   add_contrast(\"version\")  dat ## # A tibble: 8 × 6 ##   sub   stim  condition version     `condition.hard-easy` version.incongruent-…¹ ##   <chr> <chr> <fct>     <fct>                       <dbl>                  <dbl> ## 1 sub1  stim1 easy      congruent                    -0.5                   -0.5 ## 2 sub1  stim1 easy      incongruent                  -0.5                    0.5 ## 3 sub1  stim2 easy      congruent                    -0.5                   -0.5 ## 4 sub1  stim2 easy      incongruent                  -0.5                    0.5 ## 5 sub2  stim1 hard      congruent                     0.5                   -0.5 ## 6 sub2  stim1 hard      incongruent                   0.5                    0.5 ## 7 sub2  stim2 hard      congruent                     0.5                   -0.5 ## 8 sub2  stim2 hard      incongruent                   0.5                    0.5 ## # ℹ abbreviated name: ¹​`version.incongruent-congruent`"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"random-effects","dir":"Articles","previous_headings":"Simulation","what":"Random Effects","title":"Mixed Effects","text":"Now specify random effect structure. ’ll just add random intercepts start, conver random slopes later. subject slightly faster slower reaction times average; random intercept (sub_i). ’ll model normal distribution mean 0 SD 100ms. stimulus slightly faster slower reaction times average; random intercept (stim_i). ’ll model normal distribution mean 0 SD 50ms (seems reasonable expect less variability words people task). Run code times see random effects change time. sampled populations.","code":"sub_n  <- 2 # number of subjects in this simulation stim_n  <- 2 # number of stimuli in this simulation sub_sd <- 100 # SD for the subjects' random intercept stim_sd <- 50 # SD for the stimuli's random intercept  dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n) |>   add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>   add_within(version = c(\"congruent\", \"incongruent\")) |>   add_contrast(\"condition\", colnames = \"cond\") |>   add_contrast(\"version\", colnames = \"vers\") |>   add_ranef(.by = \"sub\", sub_i = sub_sd) |>   add_ranef(.by = \"stim\", stim_i = stim_sd)  dat ## # A tibble: 8 × 8 ##   sub   stim  condition version      cond  vers sub_i stim_i ##   <chr> <chr> <fct>     <fct>       <dbl> <dbl> <dbl>  <dbl> ## 1 sub1  stim1 easy      congruent    -0.5  -0.5 -99.7  -30.9 ## 2 sub1  stim1 easy      incongruent  -0.5   0.5 -99.7  -30.9 ## 3 sub1  stim2 easy      congruent    -0.5  -0.5 -99.7  101.  ## 4 sub1  stim2 easy      incongruent  -0.5   0.5 -99.7  101.  ## 5 sub2  stim1 hard      congruent     0.5  -0.5  72.2  -30.9 ## 6 sub2  stim1 hard      incongruent   0.5   0.5  72.2  -30.9 ## 7 sub2  stim2 hard      congruent     0.5  -0.5  72.2  101.  ## 8 sub2  stim2 hard      incongruent   0.5   0.5  72.2  101."},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"error-term","dir":"Articles","previous_headings":"Simulation","what":"Error Term","title":"Mixed Effects","text":"Finally, add error term. uses add_ranef() function, just without specifying random factor ’s .. essence, samples error value normal distribution mean 0 specified SD trial. ’ll also increase number subjects stimuli realistic values now.","code":"sub_n    <- 200 # number of subjects in this simulation stim_n   <- 50  # number of stimuli in this simulation sub_sd   <- 100 # SD for the subjects' random intercept stim_sd  <- 50  # SD for the stimuli's random intercept error_sd <- 25  # residual (error) SD  dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n) |>   add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>   add_within(version = c(\"congruent\", \"incongruent\")) |>   add_contrast(\"condition\", colnames = \"cond\") |>   add_contrast(\"version\", colnames = \"vers\") |>   add_ranef(.by = \"sub\", sub_i = sub_sd) |>   add_ranef(.by = \"stim\", stim_i = stim_sd) |>   add_ranef(err = error_sd)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"calculate-dv","dir":"Articles","previous_headings":"Simulation","what":"Calculate DV","title":"Mixed Effects","text":"Now can calculate DV adding together overall intercept (mean RT trials), subject-specific intercept, stimulus-specific intercept, error term, plus effect subject condition, effect stimulus version, interaction condition version. set effects raw units (ms). set effect subject condition (sub_cond_eff) 50, means average difference easy hard condition 50ms. Easy coded -0.5 hard coded +0.5, means trials easy condition -0.5 * 50ms (.e., -25ms) added reaction time, trials hard condition +0.5 * 50ms (.e., +25ms) added reaction time. always, graph make sure ’ve simulated general pattern expected. Double-check simulated pattern","code":"sub_n         <- 200 # number of subjects in this simulation stim_n        <- 50  # number of stimuli in this simulation sub_sd        <- 100 # SD for the subjects' random intercept stim_sd       <- 50  # SD for the stimuli's random intercept error_sd      <- 25  # residual (error) SD grand_i       <- 400 # overall mean DV cond_eff      <- 50  # mean difference between conditions: hard - easy vers_eff      <- 50  # mean difference between versions: incongruent - congruent cond_vers_ixn <-  0  # interaction between version and condition  dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n) |>   add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>   add_within(version = c(\"congruent\", \"incongruent\")) |>   add_contrast(\"condition\", colnames = \"cond\") |>   add_contrast(\"version\", colnames = \"vers\") |>   add_ranef(.by = \"sub\", sub_i = sub_sd) |>   add_ranef(.by = \"stim\", stim_i = stim_sd) |>   add_ranef(err = error_sd) |>   mutate(dv = grand_i + sub_i + stim_i + err +          (cond * cond_eff) +           (vers * vers_eff) +           (cond * vers * cond_vers_ixn) # in this example, this is always 0 and could be omitted   ) ggplot(dat, aes(condition, dv, color = version)) +   geom_hline(yintercept = grand_i) +   geom_violin(alpha = 0.5) +   stat_summary(fun = mean,                fun.min = \\(x){mean(x) - sd(x)},                fun.max = \\(x){mean(x) + sd(x)},                position = position_dodge(width = 0.9)) +   scale_color_brewer(palette = \"Dark2\")"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"interactions","dir":"Articles","previous_headings":"Simulation","what":"Interactions","title":"Mixed Effects","text":"want simulate interaction, can tricky figure set main effects interaction effect . can easier think simple main effects cell. Create four new variables set deviations overall mean ’d expect condition (add 0). , ’re simulating small effect version hard condition (50ms difference) double effect version easy condition (100ms difference). Use code transform simple main effects main effects interactions use equations . generate DV way , also add interaction effect multiplied effect-coded subject condition stimulus version. Double-check interaction condition version","code":"# set variables to use in calculations below hard_congr <- -25 hard_incon <- +25 easy_congr <- -50 easy_incon <- +50 # calculate main effects and interactions from simple effects above  # mean difference between easy and hard conditions cond_eff     <- (hard_congr + hard_incon)/2 -                 (easy_congr + easy_incon)/2  # mean difference between incongruent and congruent versions vers_eff <- (hard_incon + easy_incon)/2 -              (hard_congr + easy_congr)/2  # interaction between version and condition cond_vers_ixn <- (hard_incon - hard_congr) -                  (easy_incon - easy_congr) dat <- add_random(sub = sub_n) |>   add_random(stim = stim_n) |>   add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>   add_within(version = c(\"congruent\", \"incongruent\")) |>   add_contrast(\"condition\", colnames = \"cond\") |>   add_contrast(\"version\", colnames = \"vers\") |>   add_ranef(.by = \"sub\", sub_i = sub_sd) |>   add_ranef(.by = \"stim\", stim_i = stim_sd) |>   add_ranef(err = error_sd) |>   mutate(dv = grand_i + sub_i + stim_i + err +          (cond * cond_eff) +           (vers * vers_eff) +           (cond * vers * cond_vers_ixn)   ) ggplot(dat, aes(condition, dv, color = version)) +   geom_hline(yintercept = grand_i) +   geom_violin(alpha = 0.5) +   stat_summary(fun = mean,                fun.min = \\(x){mean(x) - sd(x)},                fun.max = \\(x){mean(x) + sd(x)},                position = position_dodge(width = 0.9)) +   scale_color_brewer(palette = \"Dark2\") group_by(dat, condition, version) %>%   summarise(m = mean(dv) - grand_i %>% round(1),             .groups = \"drop\") %>%   pivot_wider(names_from = version,                values_from = m) ## # A tibble: 2 × 3 ##   condition congruent incongruent ##   <fct>         <dbl>       <dbl> ## 1 easy          -53.4        46.7 ## 2 hard          -18.6        31.0"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"Mixed Effects","text":"New run linear mixed effects model lmer look summary.","code":"mod <- lmer(dv ~ cond * vers +               (1 | sub) +                (1 | stim),             data = dat)  mod.sum <- summary(mod)  mod.sum ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: dv ~ cond * vers + (1 | sub) + (1 | stim) ##    Data: dat ##  ## REML criterion at convergence: 187474 ##  ## Scaled residuals:  ##    Min     1Q Median     3Q    Max  ## -4.154 -0.668  0.000  0.674  4.604  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  sub      (Intercept) 12456    111.6    ##  stim     (Intercept)  2755     52.5    ##  Residual               628     25.1    ## Number of obs: 20000, groups:  sub, 200; stim, 50 ##  ## Fixed effects: ##              Estimate Std. Error        df t value Pr(>|t|)     ## (Intercept)   401.417     10.835   168.868   37.05   <2e-16 *** ## cond            9.554     15.788   198.000    0.61     0.55     ## vers           74.834      0.354 19749.000  211.16   <2e-16 *** ## cond:vers     -50.516      0.709 19749.000  -71.27   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) cond  vers  ## cond      0.000              ## vers      0.000  0.000       ## cond:vers 0.000  0.000 0.000"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"sense-checks","dir":"Articles","previous_headings":"Analysis","what":"Sense checks","title":"Mixed Effects","text":"First, check groups make sense. number obs total number trials analysed. sub set sub_n . stim set stim_n . Next, look random effects. SD sub near sub_sd. SD stim near stim_sd. residual SD near error_sd. Finally, look fixed effects. estimate Intercept near grand_i. main effect cond near calculated cond_eff. main effect vers near calculated vers_eff. interaction cond:vers near calculated cond_vers_ixn.","code":"mod.sum$ngrps |>   as_tibble(rownames = \"Random.Fator\") |>   mutate(parameters = c(sub_n, stim_n)) ## # A tibble: 2 × 3 ##   Random.Fator value parameters ##   <chr>        <dbl>      <dbl> ## 1 sub            200        200 ## 2 stim            50         50 mod.sum$varcor |>   as_tibble() |>   select(Groups = grp, Name = var1, \"Std.Dev.\" = sdcor) |>   mutate(parameters = c(sub_sd, stim_sd, error_sd)) ## # A tibble: 3 × 4 ##   Groups   Name        Std.Dev. parameters ##   <chr>    <chr>          <dbl>      <dbl> ## 1 sub      (Intercept)    112.         100 ## 2 stim     (Intercept)     52.5         50 ## 3 Residual NA              25.1         25 mod.sum$coefficients |>   as_tibble(rownames = \"Effect\") |>   select(Effect, Estimate) |>   mutate(parameters = c(grand_i, cond_eff, vers_eff, cond_vers_ixn)) ## # A tibble: 4 × 3 ##   Effect      Estimate parameters ##   <chr>          <dbl>      <dbl> ## 1 (Intercept)   401.          400 ## 2 cond            9.55          0 ## 3 vers           74.8          75 ## 4 cond:vers     -50.5         -50"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"random-effects-1","dir":"Articles","previous_headings":"Analysis","what":"Random effects","title":"Mixed Effects","text":"Plot subject intercepts code (dat$sub_i) subject intercepts calculated lmer (ranef(mod)$sub_id). Compare simulated subject random intercepts model Plot stimulus intercepts code (dat$stim_i) stimulus intercepts calculated lmer (ranef(mod)$stim_id). Compare simulated stimulus random intercepts model","code":"# get simulated random intercept for each subject sub_sim <- dat |>   group_by(sub, sub_i) |>   summarise(.groups = \"drop\")  # join to calculated random intercept from model sub_sim_mod <- ranef(mod)$sub |>   as_tibble(rownames = \"sub\") |>   rename(mod_sub_i = `(Intercept)`) |>   left_join(sub_sim, by = \"sub\")  # plot to check correspondence sub_sim_mod |>   ggplot(aes(sub_i,mod_sub_i)) +   geom_point() +   geom_smooth(method = \"lm\", formula = y~x) +   xlab(\"Simulated random intercepts (sub_i)\") +   ylab(\"Modeled random intercepts\") # get simulated random intercept for each stimulus stim_sim <- dat |>   group_by(stim, stim_i) |>   summarise(.groups = \"drop\")  # join to calculated random intercept from model stim_sim_mod <- ranef(mod)$stim |>   as_tibble(rownames = \"stim\") |>   rename(mod_stim_i = `(Intercept)`) |>   left_join(stim_sim, by = \"stim\")  # plot to check correspondence stim_sim_mod |>   ggplot(aes(stim_i,mod_stim_i)) +   geom_point() +   geom_smooth(method = \"lm\", formula = y~x) +   xlab(\"Simulated random intercepts (stim_i)\") +   ylab(\"Modeled random intercepts\")"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"function","dir":"Articles","previous_headings":"Analysis","what":"Function","title":"Mixed Effects","text":"can put code function can run easily change parameters. removed plot set argument defaults example fixed effects set 0, can set patterns. Run function default values (fixed effects set 0). Try changing variables simulate different patterns fixed effects.","code":"sim_lmer <- function( sub_n = 200,                       stim_n = 50,                       sub_sd = 100,                       stim_sd = 50,                       error_sd = 25,                       grand_i = 400,                       cond_eff = 0,                       vers_eff = 0,                        cond_vers_ixn = 0) {   dat <- add_random(sub = sub_n) |>     add_random(stim = stim_n) |>     add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>     add_within(version = c(\"congruent\", \"incongruent\")) |>     add_contrast(\"condition\", colnames = \"cond\") |>     add_contrast(\"version\", colnames = \"vers\") |>     add_ranef(.by = \"sub\", sub_i = sub_sd) |>     add_ranef(.by = \"stim\", stim_i = stim_sd) |>     add_ranef(err = error_sd) |>     mutate(dv = grand_i + sub_i + stim_i + err +            (cond * cond_eff) +             (vers * vers_eff) +             (cond * vers * cond_vers_ixn)     )      mod <- lmer(dv ~ cond * vers +                 (1 | sub) +                  (1 | stim),               data = dat)      return(mod) } sim_lmer() %>% summary() ## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : ## Model failed to converge with max|grad| = 0.00215933 (tol = 0.002, component 1) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: dv ~ cond * vers + (1 | sub) + (1 | stim) ##    Data: dat ##  ## REML criterion at convergence: 187222 ##  ## Scaled residuals:  ##    Min     1Q Median     3Q    Max  ## -4.191 -0.666  0.005  0.671  3.958  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  sub      (Intercept) 11254    106.1    ##  stim     (Intercept)  3062     55.3    ##  Residual               620     24.9    ## Number of obs: 20000, groups:  sub, 200; stim, 50 ##  ## Fixed effects: ##              Estimate Std. Error        df t value Pr(>|t|)     ## (Intercept)   399.955     10.842   149.164   36.89   <2e-16 *** ## cond           14.384     15.007   198.045    0.96     0.34     ## vers           -0.111      0.352 19748.984   -0.31     0.75     ## cond:vers       0.817      0.705 19748.984    1.16     0.25     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) cond  vers  ## cond      0.000              ## vers      0.000  0.000       ## cond:vers 0.000  0.000 0.000 ## optimizer (nloptwrap) convergence code: 0 (OK) ## Model failed to converge with max|grad| = 0.00215933 (tol = 0.002, component 1) sim_lmer(cond_eff = 0,          vers_eff = 75,           cond_vers_ixn = -50) %>%   summary() ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: dv ~ cond * vers + (1 | sub) + (1 | stim) ##    Data: dat ##  ## REML criterion at convergence: 187381 ##  ## Scaled residuals:  ##    Min     1Q Median     3Q    Max  ## -4.761 -0.674 -0.007  0.665  3.875  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  sub      (Intercept) 9410     97.0     ##  stim     (Intercept) 2260     47.5     ##  Residual              627     25.0     ## Number of obs: 20000, groups:  sub, 200; stim, 50 ##  ## Fixed effects: ##              Estimate Std. Error        df t value Pr(>|t|)     ## (Intercept)   396.707      9.606   160.846   41.30   <2e-16 *** ## cond           -9.966     13.723   198.000   -0.73     0.47     ## vers           75.323      0.354 19749.000  212.69   <2e-16 *** ## cond:vers     -49.997      0.708 19749.000  -70.59   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) cond  vers  ## cond      0.000              ## vers      0.000  0.000       ## cond:vers 0.000  0.000 0.000"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"power-analysis","dir":"Articles","previous_headings":"Analysis","what":"Power analysis","title":"Mixed Effects","text":"First, wrap simulation function inside another function takes argument replication number, runs simulated analysis, returns data table fixed random effects (made broom.mixed::tidy()). can use purrr’s map_df() function create data table results multiple replications function. ’re running 10 replications interests time, ’ll want run 100 proper power calculation. can plot distribution estimates across simulations.  can also just calculate power proportion p-values less alpha.","code":"sim_lmer_pwr <- function(rep) {   s <- sim_lmer(cond_eff = 0,                 vers_eff = 75,                  cond_vers_ixn = 50)      # put just the fixed effects into a data table   broom.mixed::tidy(s, \"fixed\") %>%     mutate(rep = rep) # add a column for which rep }  my_power <- map_df(1:10, sim_lmer_pwr) ggplot(my_power, aes(estimate, color = term)) +   geom_density() +   facet_wrap(~term, scales = \"free\") my_power %>%   group_by(term) %>%   summarise(power = mean(p.value < 0.05),             .groups = \"drop\") ## # A tibble: 4 × 2 ##   term        power ##   <chr>       <dbl> ## 1 (Intercept)   1   ## 2 cond          0.1 ## 3 cond:vers     1   ## 4 vers          1"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"random-slopes","dir":"Articles","previous_headings":"","what":"Random slopes","title":"Mixed Effects","text":"example far ’ve ignored random variation among subjects stimuli size fixed effects (.e., random slopes). First, let’s reset parameters set .","code":"sub_n         <- 200 # number of subjects in this simulation stim_n        <- 50  # number of stimuli in this simulation sub_sd        <- 100 # SD for the subjects' random intercept stim_sd       <- 50  # SD for the stimuli's random intercept error_sd      <- 25  # residual (error) SD grand_i       <- 400 # overall mean DV cond_eff      <- 50  # mean difference between conditions: hard - easy vers_eff      <- 50  # mean difference between versions: incongruent - congruent cond_vers_ixn <-  0  # interaction between version and condition"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"slopes","dir":"Articles","previous_headings":"Random slopes","what":"Slopes","title":"Mixed Effects","text":"addition generating random intercept subject, now also generate random slope within-subject factors. within-subject factor design version. main effect version set 50 , different subjects show variation size effect. ’s random slope captures. ’ll set sub_vers_sd SD variation use calculate random slope (sub_version_slope) subject. Also, ’s likely variation subjects size effect version related way -subject variation intercept. want random intercept slope correlated. , ’ll simulate case subjects slower (larger) reaction times across board show smaller effect condition, set sub_i_vers_cor negative number (-0.2). just edit first add_ranef() add two variables (sub_i, sub_vers_slope) correlated r = -0.2, means 0, SDs equal set sub_sd sub_vers_sd .","code":"sub_vers_sd <- 20 sub_i_vers_cor <- -0.2  dat <- add_random(sub = sub_n) |>     add_random(stim = stim_n) |>     add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>     add_within(version = c(\"congruent\", \"incongruent\")) |>     add_contrast(\"condition\", colnames = \"cond\") |>     add_contrast(\"version\", colnames = \"vers\") |>     add_ranef(.by = \"sub\", sub_i = sub_sd,                sub_vers_slope = sub_vers_sd,               .cors = sub_i_vers_cor)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"correlated-slopes","dir":"Articles","previous_headings":"Random slopes","what":"Correlated Slopes","title":"Mixed Effects","text":"addition generating random intercept stimulus, also generate random slope within-stimulus factors. version condition within-stimulus factors (.e., stimuli seen congruent incongruent versions easy hard conditions). main effects version condition (interaction) vary depending stimulus. also correlated, complex way . need set correlations pairs slopes intercept. Let’s set correlation random intercept slopes -0.4 slopes correlate +0.2 (set six correlations separately want, though).","code":"stim_vers_sd <- 10 # SD for the stimuli's random slope for stim_version stim_cond_sd <- 30 # SD for the stimuli's random slope for sub_cond stim_cond_vers_sd <- 15 # SD for the stimuli's random slope for sub_cond:stim_version stim_i_cor <- -0.4 # correlations between intercept and slopes stim_s_cor <- +0.2 # correlations among slopes  # specify correlations for rnorm_multi (one of several methods) stim_cors <- c(stim_i_cor, stim_i_cor, stim_i_cor,                            stim_s_cor, stim_s_cor,                                        stim_s_cor)  dat <- add_random(sub = sub_n) |>     add_random(stim = stim_n) |>     add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>     add_within(version = c(\"congruent\", \"incongruent\")) |>     add_contrast(\"condition\", colnames = \"cond\") |>     add_contrast(\"version\", colnames = \"vers\") |>     add_ranef(.by = \"sub\", sub_i = sub_sd,                sub_vers_slope = sub_vers_sd,               .cors = sub_i_vers_cor) |>     add_ranef(.by = \"stim\", stim_i = stim_sd,               stim_vers_slope = stim_vers_sd,               stim_cond_slope = stim_cond_sd,               stim_cond_vers_slope = stim_cond_vers_sd,               .cors = stim_cors)"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"calculate-dv-1","dir":"Articles","previous_headings":"Random slopes","what":"Calculate DV","title":"Mixed Effects","text":"Now can calculate DV adding together overall intercept (mean RT trials), subject-specific intercept, stimulus-specific intercept, effect subject condition, stimulus-specific slope condition, effect stimulus version, stimulus-specific slope version, subject-specific slope condition, interaction condition version (set 0 example), stimulus-specific slope interaction condition version, error term. always, graph make sure ’ve simulated general pattern expected. Double-check simulated pattern","code":"dat <- add_random(sub = sub_n) |>     add_random(stim = stim_n) |>     add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>     add_within(version = c(\"congruent\", \"incongruent\")) |>     add_contrast(\"condition\", colnames = \"cond\") |>     add_contrast(\"version\", colnames = \"vers\") |>     add_ranef(.by = \"sub\", sub_i = sub_sd,                sub_vers_slope = sub_vers_sd,               .cors = sub_i_vers_cor) |>     add_ranef(.by = \"stim\", stim_i = stim_sd,               stim_vers_slope = stim_vers_sd,               stim_cond_slope = stim_cond_sd,               stim_cond_vers_slope = stim_cond_vers_sd,               .cors = stim_cors) |>     add_ranef(err = error_sd) |>   mutate(     trial_cond_eff = cond_eff + stim_cond_slope,     trial_vers_eff = vers_eff + sub_vers_slope + stim_vers_slope,     trial_cond_vers_ixn = cond_vers_ixn + stim_cond_vers_slope,     dv = grand_i + sub_i + stim_i + err +          (cond * trial_cond_eff) +           (vers * trial_vers_eff) +           (cond * vers * trial_cond_vers_ixn)   ) ggplot(dat, aes(condition, dv, color = version)) +   geom_hline(yintercept = grand_i) +   geom_violin(alpha = 0.5) +   stat_summary(fun = mean,                fun.min = \\(x){mean(x) - sd(x)},                fun.max = \\(x){mean(x) + sd(x)},                position = position_dodge(width = 0.9)) +   scale_color_brewer(palette = \"Dark2\")"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"analysis-1","dir":"Articles","previous_headings":"","what":"Analysis","title":"Mixed Effects","text":"New ’ll run linear mixed effects model lmer look summary. specify random slopes adding within-level effects random intercept specifications. Since within-subject factor version, random effects specification subjects (1 + vers | sub). Since condition version within-stimuli factors, random effects specification stimuli (1 + vers*cond | stim). model take lot longer run one without random slopes specified. might good time coffee break.","code":"mod <- lmer(dv ~ cond * vers +               (1 + vers || sub) +                (1 + vers*cond || stim),             data = dat)  mod.sum <- summary(mod)  mod.sum ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: dv ~ cond * vers + (1 + vers || sub) + (1 + vers * cond || stim) ##    Data: dat ##  ## REML criterion at convergence: 188362 ##  ## Scaled residuals:  ##    Min     1Q Median     3Q    Max  ## -3.713 -0.672  0.003  0.667  3.928  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  sub      (Intercept) 9969.0   99.84    ##  sub.1    vers         369.5   19.22    ##  stim     (Intercept) 4055.8   63.68    ##  stim.1   vers          81.7    9.04    ##  stim.2   cond        1099.1   33.15    ##  stim.3   vers:cond    225.7   15.02    ##  Residual              623.8   24.98    ## Number of obs: 20000, groups:  sub, 200; stim, 50 ##  ## Fixed effects: ##             Estimate Std. Error     df t value  Pr(>|t|)     ## (Intercept)   412.57      11.45 116.78   36.05   < 2e-16 *** ## cond           73.93      14.88 232.50    4.97 0.0000013 *** ## vers           46.66       1.90 157.13   24.57   < 2e-16 *** ## cond:vers      -4.00       3.52 185.98   -1.14      0.26     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) cond  vers  ## cond      0.000              ## vers      0.000  0.000       ## cond:vers 0.000  0.000 0.000"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"sense-checks-1","dir":"Articles","previous_headings":"Analysis","what":"Sense checks","title":"Mixed Effects","text":"First, check groups make sense. sub = sub_n (200) stim = stim_n (50) Next, look SDs random effects. (Intercept) ~= sub_sd vers ~= sub_vers_sd (Intercept) ~= stim_sd vers ~= stim_vers_sd cond ~= stim_cond_sd vers:cond ~= stim_cond_vers_sd Residual ~= error_sd correlations bit difficult parse. first column Corr shows correlation random slope row random intercept. vers sub, correlation close sub_i_vers_cor. three random slopes stim, correlation random intercept near stim_i_cor correlations near stim_s_cor. Finally, look fixed effects. (Intercept) ~= grand_i sub_cond.e ~= sub_cond_eff stim_version.e ~= stim_vers_eff sub_cond.e:stim_version.e ~= cond_vers_ixn","code":"mod.sum$ngrps |>   as_tibble(rownames = \"Random.Fator\") |>   mutate(parameters = c(sub_n, stim_n)) ## # A tibble: 2 × 3 ##   Random.Fator value parameters ##   <chr>        <dbl>      <dbl> ## 1 sub            200        200 ## 2 stim            50         50 mod.sum$varcor |>   as_tibble() |>   select(Groups = grp, Name = var1, \"Std.Dev.\" = sdcor) |>   mutate(parameters = c(sub_sd, sub_vers_sd, stim_sd, stim_vers_sd, stim_cond_sd, stim_cond_vers_sd, error_sd)) ## # A tibble: 7 × 4 ##   Groups   Name        Std.Dev. parameters ##   <chr>    <chr>          <dbl>      <dbl> ## 1 sub      (Intercept)    99.8         100 ## 2 sub.1    vers           19.2          20 ## 3 stim     (Intercept)    63.7          50 ## 4 stim.1   vers            9.04         10 ## 5 stim.2   cond           33.2          30 ## 6 stim.3   vers:cond      15.0          15 ## 7 Residual NA             25.0          25 mod.sum$coefficients |>   as_tibble(rownames = \"Effect\") |>   select(Effect, Estimate) |>   mutate(parameters = c(grand_i, cond_eff, vers_eff, cond_vers_ixn)) ## # A tibble: 4 × 3 ##   Effect      Estimate parameters ##   <chr>          <dbl>      <dbl> ## 1 (Intercept)   413.          400 ## 2 cond           73.9          50 ## 3 vers           46.7          50 ## 4 cond:vers      -4.00          0"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"function-1","dir":"Articles","previous_headings":"Analysis","what":"Function","title":"Mixed Effects","text":"can put code function can run easily change parameters. removed plot set argument defaults example , can set patterns. Run function default values (null fixed effects). Try changing variables simulate fixed effects.","code":"sim_lmer_slope <- function( sub_n = 200,                             stim_n = 50,                             sub_sd = 100,                             sub_vers_sd = 20,                              sub_i_vers_cor = -0.2,                             stim_sd = 50,                             stim_vers_sd = 10,                             stim_cond_sd = 30,                             stim_cond_vers_sd = 15,                             stim_i_cor = -0.4,                             stim_s_cor = +0.2,                             error_sd = 25,                             grand_i = 400,                             sub_cond_eff = 0,                             stim_vers_eff = 0,                              cond_vers_ixn = 0) {   dat <- add_random(sub = sub_n) |>     add_random(stim = stim_n) |>     add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>     add_within(version = c(\"congruent\", \"incongruent\")) |>     add_contrast(\"condition\", colnames = \"cond\") |>     add_contrast(\"version\", colnames = \"vers\") |>     add_ranef(.by = \"sub\", sub_i = sub_sd,                sub_vers_slope = sub_vers_sd,               .cors = sub_i_vers_cor) |>     add_ranef(.by = \"stim\", stim_i = stim_sd,               stim_vers_slope = stim_vers_sd,               stim_cond_slope = stim_cond_sd,               stim_cond_vers_slope = stim_cond_vers_sd,               .cors = stim_cors) |>     add_ranef(err = error_sd) |>     mutate(       trial_cond_eff = cond_eff + stim_cond_slope,       trial_vers_eff = vers_eff + sub_vers_slope + stim_vers_slope,       trial_cond_vers_ixn = cond_vers_ixn + stim_cond_vers_slope,       dv = grand_i + sub_i + stim_i + err +            (cond * trial_cond_eff) +             (vers * trial_vers_eff) +             (cond * vers * trial_cond_vers_ixn)     )      mod <- lmer(dv ~ cond * vers +                 (1 + vers || sub) +                  (1 + vers*cond || stim),               data = dat)      return(mod) } sim_lmer_slope() %>% summary() ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: dv ~ cond * vers + (1 + vers || sub) + (1 + vers * cond || stim) ##    Data: dat ##  ## REML criterion at convergence: 188480 ##  ## Scaled residuals:  ##    Min     1Q Median     3Q    Max  ## -3.865 -0.661 -0.001  0.667  3.989  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  sub      (Intercept) 9836.4   99.18    ##  sub.1    vers         363.3   19.06    ##  stim     (Intercept) 2008.3   44.81    ##  stim.1   vers          97.1    9.85    ##  stim.2   cond         972.5   31.18    ##  stim.3   vers:cond    206.3   14.36    ##  Residual              629.0   25.08    ## Number of obs: 20000, groups:  sub, 200; stim, 50 ##  ## Fixed effects: ##             Estimate Std. Error     df t value Pr(>|t|)     ## (Intercept)   393.75       9.45 176.71   41.65  < 2e-16 *** ## cond           51.31      14.71 229.84    3.49  0.00058 *** ## vers           46.13       1.97 141.94   23.41  < 2e-16 *** ## cond:vers      -2.55       3.45 190.63   -0.74  0.45979     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) cond  vers  ## cond      0.000              ## vers      0.000  0.000       ## cond:vers 0.000  0.000 0.000 sim_lmer_slope(sub_cond_eff = 50,                stim_vers_eff = 50,                 cond_vers_ixn = 0) ## Linear mixed model fit by REML ['lmerModLmerTest'] ## Formula: dv ~ cond * vers + (1 + vers || sub) + (1 + vers * cond || stim) ##    Data: dat ## REML criterion at convergence: 188364 ## Random effects: ##  Groups   Name        Std.Dev. ##  sub      (Intercept) 102.79   ##  sub.1    vers         20.38   ##  stim     (Intercept)  54.20   ##  stim.1   vers          9.05   ##  stim.2   cond         31.91   ##  stim.3   vers:cond    16.82   ##  Residual              24.96   ## Number of obs: 20000, groups:  sub, 200; stim, 50 ## Fixed Effects: ## (Intercept)         cond         vers    cond:vers   ##      404.57        60.31        46.06        -2.81"},{"path":"https://debruine.github.io/data-sim-workshops/articles/mixed.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Mixed Effects","text":"Calculate power parameters last example using sim_lmer_slope() function. Simulate data following design: 100 raters rate 50 faces group 50 faces group B DV mean value 50 Group B values 5 points higher group Rater intercepts SD 5 Face intercepts SD 10 residual error SD 8 design exercise 2, write function simulates data runs mixed effects analysis . package faux built-dataset called fr4. Type ?faux::fr4 console view help dataset. Run mixed effects model dataset looking effect face_sex ratings. Remember include random slope effect face sex explicitly add contrast code. Use parameters analysis simulate new dataset 50 male 50 female faces, 100 raters.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lisa DeBruine. Author, maintainer.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"DeBruine L (2024). dsw: Data Simulation Workshops. R package version 0.0.0.9007,  https://debruine.github.io/data-sim-workshops/, https://github.com/debruine/data-sim-workshops.","code":"@Manual{,   title = {dsw: Data Simulation Workshops},   author = {Lisa DeBruine},   year = {2024},   note = {R package version 0.0.0.9007,  https://debruine.github.io/data-sim-workshops/},   url = {https://github.com/debruine/data-sim-workshops}, }"},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"data-simulation-workshop-materials-","dir":"","previous_headings":"","what":"Data Simulation Workshops","title":"Data Simulation Workshops","text":"able simulate data allows : prep analysis scripts pre-registration calculate power sensitivity analyses don’t empirical methods create reproducible examples data big confidential share enhance understanding statistical concepts create demo data teaching tutorials","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Data Simulation Workshops","text":"can install packages used tutorials get function makes easy access workshop .Rmd files running following code: can load exercises following code: Alternatively, download stub files install specific packages workshop. faux-stub.Rmd calories-stub.Rmd fixed-stub.Rmd mixed-stub.Rmd","code":"devtools::install_github(\"debruine/data-sim-workshops\") dsw::exercise(\"faux\") dsw::exercise(\"calories\") dsw::exercise(\"fixed\") dsw::exercise(\"mixed\")"},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"upcoming-workshops","dir":"","previous_headings":"","what":"Upcoming Workshops","title":"Data Simulation Workshops","text":": 2024 February 1-2 : Data Simulation Workshop 2024, Institute Psychology, Bern , Switzerland","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"data-simulation-with-faux","dir":"","previous_headings":"Upcoming Workshops","what":"Data Simulation with {faux}","title":"Data Simulation Workshops","text":"session cover basics simulation using {faux}. simulate data factorial designs specifying within -subjects factor structure, cell mean standard deviation, correlations cells appropriate. can used create simulated data sets used preparing analysis code pre-registrations registered reports. also create data sets simulation-based power analyses. Students need basic knowledge R R Markdown, installed {faux}, {afex}, {broom} {tidyverse}.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"prep","dir":"","previous_headings":"Upcoming Workshops > Data Simulation with {faux}","what":"Prep","title":"Data Simulation Workshops","text":"Install R packages CRAN: tidyverse, afex, faux, broom Download files: faux-stub.Rmd","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"data-simulation-for-mixed-designs","dir":"","previous_headings":"Upcoming Workshops","what":"Data simulation for mixed designs","title":"Data Simulation Workshops","text":"session cover simulating data mixed design, trials crossed subjects. learn analyse using {lme4}, focus understanding simulation parameters correspond output. Finally, learn use simulation calculate power. Students need basic knowledge R R Markdown, familiarity mixed designs (even don’t currently analyse mixed models) installed {faux}, {afex}, {tidyverse}, {lme4}.","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"prep-1","dir":"","previous_headings":"Upcoming Workshops > Data simulation for mixed designs","what":"Prep","title":"Data Simulation Workshops","text":"Install R packages CRAN: tidyverse, afex, lme4, broom, broom.mixed, faux Download files: mixed-stub.Rmd","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"Data Simulation Workshops","text":"Faux Shiny App Data Skills Reproducible Research open source textbook introducing tidyverse psychologists Understanding mixed effects models data simulation (preprint, code, shiny apps) Simulate Basic Distributions","code":""},{"path":"https://debruine.github.io/data-sim-workshops/index.html","id":"past-workshops","dir":"","previous_headings":"","what":"Past Workshops","title":"Data Simulation Workshops","text":"Vrije Universiteit Amsterdam, NL Fake Make : simulate research data 2023 September 20 Max Planck Institute Evolutionary Anthropology, Leipzig, Germany Simulating data {faux} 2023 July 27 9:00 - 12:00 (CET) European Evolutionary Biology Conference, Millport, Scotland Fake Make : simulate research data 2023 June 1 14:30 - 16:30 (GMT) University Glasgow Institute Neuroscience & Psychology Data Simulation {faux} 2023 January 18 12:00 - 13:00 (GMT) Netherlands Institute Study Crime Law Enforcement Data Simulation {faux} 2022 December 6 13:00 - 14:00 (CET) Polish Association Social Psychology Conference, Gdánsk Data simulation fixed effects Data simulation mixed designs Practical Session 2022 September 14 09:00 - 16:00 (CET) RLadies Glasgow Data simulation using faux 2022 May 24 15:00-17:00 (BST) University York Data simulation factorial designs Data simulation mixed designs 2022 April 27 09:00-17:00 (BST) Proposal Publication: Pathways Open Science Data simulation factorial designs Data simulation mixed designs 2022 July 13 13:30-17:00 University Glasgow Institute Neuroscience Psychology 2020 Jan 28 13:00-15:00 Feb 5 14:00-16:00 University Grenoble Understanding Mixed-Effects Models Data Simulation 2021 February 5 13:00-15:00 PsyPAG Data Simulation Summer School Simulation factorial designs faux 2021 June 4 13:00-15:00","code":""},{"path":"https://debruine.github.io/data-sim-workshops/reference/exercise.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an exercise — exercise","title":"Get an exercise — exercise","text":"Get exercise","code":""},{"path":"https://debruine.github.io/data-sim-workshops/reference/exercise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an exercise — exercise","text":"","code":"exercise(name = c(\"faux\", \"fixed\", \"mixed\", \"calories\"), filename = NULL)"},{"path":"https://debruine.github.io/data-sim-workshops/reference/exercise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an exercise — exercise","text":"name name exercise filename filename want save (defaults name exercise working directory)","code":""},{"path":"https://debruine.github.io/data-sim-workshops/reference/exercise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get an exercise — exercise","text":"Saves file working directory (path filename)","code":""},{"path":"https://debruine.github.io/data-sim-workshops/reference/exercise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get an exercise — exercise","text":"","code":"if (FALSE) { exercise(\"faux\") # get exercise for the faux workshop exercise(\"fixed\", \"exercises/fixed.Rmd\") # save into exercises directory }"}]
